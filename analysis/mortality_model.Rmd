---
title: "Mortality Modeling"
author: "Christie Yang"
date: "5/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(dplyr)
library(here)

# Mortality Data
load(here("data/cleaned-data", "usable_cases.Rdata"))
glimpse(usable_cases)

require(ggplot2)
require(reshape2)
require(lme4)
require(compiler)
require(parallel)
require(boot)
require(lattice)
```

## Mortality Dataset Logistic Regression Model  

- Akaike and Bayesian Information Criterion (AIC & BIC respectively) are two ways of scoring a model based on its log-likelihood and complexity. BIC penalizes more for model complexity than AIC and so BIC is more likely to choose simpler models.  

### Assumptions of Mortality Logistic Regression  
- 

```{r cars}
# MODEL 0: without random intercept (and hospital bed data and housing data)
model_0 <- glm(
    formula = death_due_to_covid  ~ decades_old + gender + race + 
              adj_perc_bach_quar + adj_perc_insured_quar +
              adj_pop_density + adj_med_income +
              adj_time_days,
    family = binomial, 
    data = usable_cases
    )


print(summary(model_0))
print(BIC(model_0))
```


```{r}
# MODEL 1: with random intercept (without hospital bed data)
# ERROR: "Model failed to converge with max|grad|"
# Solution: control parameter 
model_1 <- glmer(
    formula = death_due_to_covid  ~ decades_old + gender + race + 
              adj_perc_bach_quar + adj_perc_insured_quar +
              adj_pop_density + adj_med_income +
              adj_time_days + (1|zip),
    family = binomial, 
    data = usable_cases,
    control = glmerControl(optimizer ="bobyqa", optCtrl = list(maxfun = 2e6))
    )

print(summary(model_1))
print(BIC(model_1))
```
```{r}
compare_bic <- BIC(model_0, model_1) 
row.names(compare_bic) <- c("Model 0", "Model 1")
compare_bic
```
Model 1 has an additional random intercept that factors in zip code. This model 
has a lower BIC score than model 0 and is a better model. 



